training: 
    weight_decay: 0.0
    learning_rate: 1e-5
    per_device_eval_batch_size: 8
    per_device_train_batch_size: 8
    num_train_epochs: 10
    lr_scheduler_type: constant
    #fp16: True
    #load_best_model_at_end: True
    #eval_strategy: epoch
    #metric_for_best_model: eval_loss
    #save_strategy: epoch
    #save_total_limit: 1
    #save_safetensors: True
    lamb: ???
    margin: ??? 
    lamb_intra: ???

model:
    id: ???
    model_type: ???
    model_name_or_path: ???

defaults:
  - data: ???